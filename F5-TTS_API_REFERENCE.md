# F5-TTS Server API Reference

This document provides a comprehensive overview of the F5-TTS server API endpoints. Use this as the specification for building a drop-in replacement server.

---

## Server Configuration

- **Framework**: FastAPI
- **Default Port**: 7860
- **Host**: 0.0.0.0
- **CORS**: Enabled for all origins (`*`)

### CORS Middleware Settings
```python
allow_origins=["*"]
allow_credentials=True
allow_methods=["*"]
allow_headers=["*"]
```

---

## Directory Structure

| Directory | Purpose |
|-----------|---------|
| `resources/` | Stores reference audio files (voice samples) |
| `outputs/` | Temporary storage for generated audio files |

---

## Startup Behavior

On server startup, the server performs a warmup synthesis:
- **Text**: `"This is a test sentence generated by the F5-TTS API."`
- **Voice**: `demo_speaker0`

This ensures the model is loaded and ready before accepting requests.

---

## API Endpoints

### 1. `GET /base_tts/`

**Purpose**: Perform text-to-speech using the default English voice only.

#### Query Parameters

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `text` | string | Yes | - | The text to synthesize |
| `speed` | float | No | 1.0 | Speech speed multiplier |

#### Response

- **Content-Type**: `audio/wav`
- **Body**: WAV audio stream

#### Example Request
```
GET /base_tts/?text=Hello%20world&speed=1.0
```

#### Internal Behavior
- Uses the built-in `default_en` voice
- Reference text: `"Some call me nature, others call me mother nature."`
- Delegates to `synthesize_speech()` internally

---

### 2. `GET /synthesize_speech/`

**Purpose**: Synthesize speech from text using a specified voice.

#### Query Parameters

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `text` | string | Yes | - | The text to synthesize |
| `voice` | string | Yes | - | Voice label (filename prefix in `resources/`) |
| `speed` | float | No | 1.0 | Speech speed multiplier |

#### Response

- **Content-Type**: `audio/wav`
- **Body**: WAV audio stream

#### Response Headers

| Header | Description |
|--------|-------------|
| `X-Elapsed-Time` | Time taken for synthesis (seconds) |
| `X-Device-Used` | Device used (`cuda:0` or `cpu`) |
| `Access-Control-Allow-Origin` | `*` |
| `Access-Control-Allow-Credentials` | `true` |
| `Access-Control-Allow-Headers` | `Origin, Content-Type, X-Amz-Date, Authorization, X-Api-Key, X-Amz-Security-Token, locale` |
| `Access-Control-Allow-Methods` | `POST, OPTIONS` |

#### Example Request
```
GET /synthesize_speech/?text=Hello%20world&voice=demo_speaker0&speed=1.0
```

#### Internal Behavior

1. **Voice Lookup**: Searches `resources/` for files starting with the `voice` parameter
   - Prefers `.wav` files
   - Converts other formats (mp3, flac, ogg) to WAV if needed

2. **Reference Text Handling**:
   - For `default_en`: Uses hardcoded reference text
   - For other voices: Transcribes the reference audio using the model's `transcribe()` method

3. **Reference Audio Processing** (for non-default voices):
   - Clips audio to max 15 seconds
   - Uses silence detection to find natural clip points
   - Removes silence from edges
   - Adds 50ms silence padding at end

4. **Synthesis Parameters**:
   - `nfe_step`: 32
   - `cfg_strength`: 2.0

#### Error Responses

| Status | Condition |
|--------|-----------|
| 400 | No matching voice found in `resources/` |
| 500 | Any other error during synthesis |

---

### 3. `POST /upload_audio/`

**Purpose**: Upload an audio file to use as a reference voice.

#### Request Format

- **Content-Type**: `multipart/form-data`

#### Form Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `audio_file_label` | string | Yes | Label/name for the voice (used as filename prefix) |
| `file` | file | Yes | Audio file to upload |

#### Constraints

| Constraint | Value |
|------------|-------|
| Allowed extensions | `wav`, `mp3`, `flac`, `ogg` |
| Max file size | 5 MB |
| Content validation | Must be valid audio (checked via `python-magic`) |

#### Response

**Success** (200):
```json
{
  "message": "File {filename} uploaded successfully with label {audio_file_label}."
}
```

**Validation Error** (200 with error field):
```json
{
  "error": "Invalid file type. Allowed types are: wav, mp3, flac, ogg"
}
```
```json
{
  "error": "File size is over limit. Max size is 5MB."
}
```
```json
{
  "error": "Invalid file content."
}
```

**Server Error** (500):
```json
{
  "detail": "error message"
}
```

#### Internal Behavior

1. Validates file extension and size
2. Validates file content using `python-magic`
3. Saves original file to `resources/{audio_file_label}.{extension}`
4. Converts to WAV and saves to `resources/{audio_file_label}.wav`

#### Example Request (curl)
```bash
curl -X POST "http://localhost:7860/upload_audio/" \
  -F "audio_file_label=my_voice" \
  -F "file=@/path/to/audio.mp3"
```

---

### 4. `POST /change_voice/`

**Purpose**: Convert the voice of an existing audio file to a different reference voice.

#### Request Format

- **Content-Type**: `multipart/form-data`

#### Form Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `reference_speaker` | string | Yes | Voice label to convert to |
| `file` | file | Yes | Audio file to convert |

#### Response

- **Content-Type**: `audio/wav`
- **Body**: WAV audio stream with converted voice

#### Internal Behavior

1. Saves uploaded audio to `outputs/input_audio.wav`
2. Finds reference speaker in `resources/` (by filename prefix)
3. Converts reference to WAV if needed
4. Transcribes the input audio using `model.transcribe()`
5. Uses the transcription as both `ref_text` and `gen_text` for voice conversion
6. Returns the converted audio

#### Error Responses

| Status | Condition |
|--------|-----------|
| 400 | No matching reference speaker found |
| 500 | Any other error during conversion |

#### Example Request (curl)
```bash
curl -X POST "http://localhost:7860/change_voice/" \
  -F "reference_speaker=demo_speaker0" \
  -F "file=@/path/to/input_audio.wav" \
  --output converted.wav
```

---

## Voice File Naming Convention

Voice files in `resources/` are matched by **prefix**:
- A voice named `demo_speaker0` matches files like:
  - `demo_speaker0.wav`
  - `demo_speaker0.mp3`
  - `demo_speaker0_v2.wav`

The server prefers `.wav` files when multiple matches exist.

---

## Audio Processing Details

### Supported Input Formats
- WAV
- MP3
- FLAC
- OGG

### Output Format
- **Format**: WAV
- **Channels**: Mono (1 channel)
- **Sample Rate**: 24000 Hz

### Reference Audio Clipping Logic

For non-default voices, reference audio is processed to be max 15 seconds:

1. **First attempt**: Split on long silence (≥1000ms, threshold -50dB)
   - Keep segments until total exceeds 15s (but at least 6s)
   
2. **Second attempt** (if still >15s): Split on short silence (≥100ms, threshold -40dB)
   - Same logic as above
   
3. **Fallback**: Hard clip at 15 seconds

After clipping:
- Remove silence from edges (threshold -42dB)
- Add 50ms silence padding at end

---

## Model Configuration

The F5-TTS model is initialized with:

| Parameter | Value |
|-----------|-------|
| `model_type` | `F5-TTS` |
| `ode_method` | `euler` |
| `use_ema` | `True` |
| `vocoder_name` | `vocos` |
| `vocab_file` | `hf://SWivid/F5-TTS/F5TTS_Base/vocab.txt` |
| `ckpt_file` | `hf://SWivid/F5-TTS/F5TTS_Base/model_1200000.safetensors` |

### Inference Parameters

| Parameter | Value |
|-----------|-------|
| `nfe_step` | 32 |
| `cfg_strength` | 2.0 |

---

## Dependencies

### Python Packages
- `fastapi`
- `uvicorn`
- `python-multipart`
- `python-magic`
- `pydub`
- `torch`
- `torchaudio`
- `soundfile`
- `cached_path`
- `f5_tts` (F5-TTS package)

### System Dependencies
- `libmagic1`
- `ffmpeg`
- `sox` with mp3 support

---

## Pre-loaded Resources

The server ships with:
- `demo_speaker0.mp3` - A demo voice for testing

On startup, if not present, the server copies:
- `default_en.wav` - Default English reference from F5-TTS package

---

## Error Handling

All endpoints return HTTP 500 with JSON body on unhandled errors:
```json
{
  "detail": "error message"
}
```

Some validation errors in `/upload_audio/` return HTTP 200 with an `error` field instead of using proper HTTP status codes (this is a quirk of the original implementation).

---

## Summary Table

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/base_tts/` | GET | TTS with default English voice |
| `/synthesize_speech/` | GET | TTS with specified voice |
| `/upload_audio/` | POST | Upload reference voice |
| `/change_voice/` | POST | Voice conversion |
